# Sparse Autoencoder - Quick Start Guide

## âœ… Current Status: WORKING

All components tested and operational:
- âœ“ Training pipeline
- âœ“ Feature extraction
- âœ“ Alignment analysis
- âœ“ Interpretable results

---

## ğŸš€ Quick Commands

### 1. Train New SAE (if needed)
```bash
python experiments/latent_factors/train_ae.py \
  --data-path experiments/latent_factors/data/custom.npz \
  --model-type topk \
  --latent-dim 64 \
  --k 16 \
  --epochs 50 \
  --device cpu \
  --output-dir experiments/latent_factors/checkpoints/my_run
```

### 2. Extract Features (get interpretable names)
```bash
python experiments/latent_factors/extract_features.py \
  --checkpoint experiments/latent_factors/checkpoints/test_run/sparse_ae_best.pt \
  --data-path experiments/latent_factors/data/custom.npz \
  --tickers-path tickers.csv \
  --top-k 10
```

### 3. Align to PPO Policy
```bash
python experiments/latent_factors/align_factors.py \
  --data-path experiments/latent_factors/data/custom.npz \
  --checkpoint experiments/latent_factors/checkpoints/test_run/sparse_ae_best.pt \
  --ridge-lambda 1e-3
```

### 4. Test & Visualize
```bash
# Quick test on samples
python experiments/latent_factors/test_sae.py

# Comprehensive analysis
python experiments/latent_factors/analysis/feature_extraction/visualize_results.py

# Summary statistics
python experiments/latent_factors/analysis/feature_extraction/summarize.py
```

---

## ğŸ“Š Current Results Summary

### Model Performance
- **Reconstruction RÂ²**: 0.77-0.79 (Excellent)
- **Sparsity**: 25% active (16/64 latents per sample)
- **Alignment RÂ²**: 0.165 (Fair - room for improvement)

### Key Discoveries
1. **VOLTAS.NS** dominates (60% of important features)
2. **Swing trading strategy** (focuses on 7-18 day lags)
3. **Volume is critical** (21% of top features)
4. **All 64 latents interpretable** (no dead neurons)

### Top 3 Latents Learned
1. **Latent 8**: VOLTAS 6-day price action + volume
2. **Latent 34**: VOLTAS 18-day historical baseline
3. **Latent 3**: VOLTAS/SRF 14-day momentum

---

## ğŸ“ Output Files

```
experiments/latent_factors/
â”œâ”€â”€ checkpoints/test_run/
â”‚   â”œâ”€â”€ sparse_ae_best.pt          # Best model
â”‚   â””â”€â”€ metrics.json                # Training history
â”‚
â””â”€â”€ analysis/feature_extraction/
    â”œâ”€â”€ top_features.json           # Feature names & weights
    â”œâ”€â”€ decoder_matrix.npz          # Full decoder (38941Ã—64)
    â”œâ”€â”€ latents_sample.npz          # Sample activations
    â”œâ”€â”€ FEATURE_ANALYSIS.md         # Full interpretation
    â”œâ”€â”€ summarize.py                # Analysis script
    â””â”€â”€ visualize_results.py        # Comprehensive viz
```

---

## ğŸ”§ Tuning Recommendations

### To Improve Alignment RÂ² (currently 0.165):

1. **Increase Latent Capacity**
   ```bash
   --latent-dim 128 --k 32
   ```

2. **Train Longer**
   ```bash
   --epochs 200 --lr 1e-4
   ```

3. **Collect More Data**
   ```bash
   python experiments/latent_factors/collect_traces.py \
     --test-start-date 2020-01-01 \
     --test-end-date 2021-12-31  # More data
   ```

4. **Reduce Stock Concentration**
   - Currently VOLTAS is 60% - consider rebalancing

---

## ğŸ¯ Next Steps

### Short Term (Now)
1. âœ“ Feature extraction working
2. âœ“ Interpretable results
3. â—‹ Improve alignment (increase latents to 128)

### Medium Term (This Week)
1. Collect more diverse training data
2. Test with different sparsity levels (k=8, 24, 48)
3. Create trading strategy visualization

### Long Term (Research)
1. Cluster latents by function (momentum/volume/correlation)
2. Ablation studies (remove specific latents)
3. Generate natural language explanations

---

## ğŸ› Troubleshooting

### "Using 'obs' instead of 'activations'"
- **Harmless warning** - backward compatibility with old data format
- To fix: Re-run `collect_traces.py` with newer version

### Low Alignment RÂ² (<0.20)
- Normal for first run
- Try: More latents (128), more data, longer training

### "Dead latent ratio > 10%"
- Check auxiliary loss weight: `--aux-weight 1e-3`
- Ensure decoder normalization is enabled

---

## ğŸ“š Documentation

- **Implementation Review**: `experiments/latent_factors/IMPLEMENTATION_REVIEW.md`
- **Feature Analysis**: `experiments/latent_factors/analysis/feature_extraction/FEATURE_ANALYSIS.md`
- **Training Changelog**: `experiments/latent_factors/CHANGELOG.md`
- **Research Paper**: `experiments/latent_factors/sparseAutoencoder.pdf`

---

## âœ¨ Key Takeaways

Your Sparse Autoencoder has successfully learned:
- **Interpretable features** (each latent = specific stock/time/feature combo)
- **Sparse representations** (25% sparsity = 16 active per sample)
- **Trading patterns** (swing strategy with 7-18 day focus)
- **Stock importance** (VOLTAS and SRF drive decisions)

**Status**: Production-ready for analysis and trading strategy refinement! ğŸš€
